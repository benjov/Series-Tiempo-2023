{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebe2e9d-685d-4ea3-ab7c-9589caaabff5",
   "metadata": {},
   "source": [
    "# Guideline for Prompt engineering\n",
    "\n",
    "## Introducción (o ¿Qué es el procesamiento del lenguaje natural?)\n",
    "\n",
    "En este momento, el procesamiento del lenguaje natural (PNL o NPL) es una de las áreas más populares de la inteligencia artificial (IA) gracias a aplicaciones como generadores de texto que:\n",
    "\n",
    "* componen ensayos coherentes\n",
    "* chatbots que engañan a las personas haciéndoles creer que son sensibles\n",
    "* programas de conversión de texto a imagen que producen imágenes fotorrealistas\n",
    "\n",
    "En los últimos modelos de IA están desbloqueando áreas en las que el texto es abundante.\n",
    "\n",
    "### ¿Qué es el procesamiento del lenguaje natural? \n",
    "\n",
    "El procesamiento del lenguaje natural es la disciplina que busca construir máquinas que puedan manipular el lenguaje humano (o datos que se asemejan al lenguaje humano) en la forma en que se escribe, se habla y se organiza. \n",
    "\n",
    "Evolucionó a partir de la lingüística computacional, que utiliza la informática para comprender los principios del lenguaje, pero en lugar de desarrollar marcos teóricos, el NLP es una disciplina de ingeniería que busca desarrollar tecnología para realizar tareas útiles. \n",
    "\n",
    "El NLP se puede dividir en dos subcampos superpuestos: \n",
    "\n",
    "* comprensión del lenguaje natural, que se centra en el análisis semántico o la determinación del significado previsto del texto, y \n",
    "* generación del lenguaje natural, que se centra en la generación de texto por una máquina. \n",
    "\n",
    "Nota: El NLP está separado del reconocimiento de voz, pero a menudo se usa junto con él, que busca analizar el lenguaje hablado en palabras, convirtiendo el sonido en texto y viceversa (ver, por ejmeplo: https://medium.com/@kbdhunga/summarizing-youtube-videos-using-openai-whisper-gpt-3-5690c9a57b78).\n",
    "\n",
    "### ¿Por qué es importante el NLP?\n",
    "\n",
    "Porque hoy día los agentes más sofisticados, como GPT-3, que recientemente se abrió para aplicaciones comerciales, pueden generar prosa sofisticada sobre una amplia variedad de temas, así como potentes chatbots capaces de mantener conversaciones coherentes. \n",
    "\n",
    "Google utiliza el NLP para mejorar los resultados de sus motores de búsqueda y redes sociales como Facebook la utilizan para detectar y filtrar el discurso de odio.\n",
    "\n",
    "El NLP es cada vez más sofisticado y será difícil dar seguimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10636ba",
   "metadata": {},
   "source": [
    "### ¿Para qué se utiliza el procesamiento del lenguaje natural (PLN)?\n",
    "\n",
    "* El análisis de sentimientos es el proceso de clasificar la intención emocional del texto.\n",
    "\n",
    "<img src=\"Sentiment.png\" alt=\"Sentiment\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e96f6d7",
   "metadata": {},
   "source": [
    "* La clasificación de toxicidad es una rama del análisis de sentimientos donde el objetivo no es sólo clasificar la intención hostil sino también clasificar categorías particulares como amenazas, insultos, obscenidades y odio hacia ciertas identidades.\n",
    "* La traducción automática automatiza la traducción entre diferentes idiomas.\n",
    "* El reconocimiento de entidades tiene como objetivo extraer entidades en un fragmento de texto en categorías predefinidas, como nombres personales, organizaciones, ubicaciones y cantidades.\n",
    "<img src=\"Entity.png\" alt=\"Sentiment\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72bd307",
   "metadata": {},
   "source": [
    "* La detección de spam es un problema de clasificación binaria frecuente en PNL, donde el propósito es clasificar los correos electrónicos como spam o no.\n",
    "* Los modelos de corrección de errores gramaticales codifican reglas gramaticales para corregir la gramática dentro del texto.\n",
    "* El modelado de temas es una tarea de minería de textos no supervisada que toma un corpus de documentos y descubre temas abstractos dentro de ese corpus.\n",
    "* La generación de texto, más formalmente conocida como generación de lenguaje natural, produce texto similar al texto escrito por humanos.\n",
    "* La recuperación de información encuentra los documentos que son más relevantes para una consulta. Este es un problema al que se enfrenta todo sistema de búsqueda y recomendación.\n",
    "<img src=\"Information.png\" alt=\"Sentiment\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d1d78",
   "metadata": {},
   "source": [
    "* El resumen es la tarea de acortar el texto para resaltar la información más relevante.\n",
    "* La respuesta a preguntas consiste en responder preguntas planteadas por humanos en un lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f4e16",
   "metadata": {},
   "source": [
    "## Principales técnicas de procesamiento del lenguaje natural (PNL)\n",
    "La mayoría de las tareas de NLP pueden modelarse mediante una docena de técnicas generales. Es útil pensar en estas técnicas en dos categorías: métodos tradicionales de aprendizaje automático y métodos de aprendizaje profundo.\n",
    "\n",
    "### Técnicas tradicionales de PNL de aprendizaje automático:\n",
    "\n",
    "* La regresión logística es un algoritmo de clasificación supervisado que tiene como objetivo predecir la probabilidad de que ocurra un evento en función de alguna entrada. En PNL, los modelos de regresión logística se pueden aplicar para resolver problemas como el análisis de sentimientos, la detección de spam y la clasificación de toxicidad.\n",
    "* Naive Bayes es un algoritmo de clasificación supervisado que encuentra la distribución de probabilidad condicional P (etiqueta | texto) utilizando la fórmula de Bayes.\n",
    "\n",
    "Por ejemplo:\n",
    "<img src=\"Tree.png\" alt=\"Sentiment\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f2a57b",
   "metadata": {},
   "source": [
    "### Deep learning NLP Techniques: \n",
    "\n",
    "Algunos modelos populares son:\n",
    "* BERT y sus amigos Muppet: muchos modelos de aprendizaje profundo para PNL llevan el nombre de personajes de los Muppet, incluidos ELMo, BERT, Big BIRD, ERNIE, Kermit, Grover, RoBERTa y Rosita. La mayoría de estos modelos son buenos para proporcionar incorporaciones contextuales y una representación mejorada del conocimiento.\n",
    "* Generative Pre-Trained Transformer 3 (GPT-3) es un modelo de 175 mil millones de parámetros que puede escribir prosa original con fluidez equivalente a la humana en respuesta a una solicitud de entrada. El modelo se basa en la arquitectura del transformador. La versión anterior, GPT-2, es de código abierto. Microsoft adquirió una licencia exclusiva para acceder al modelo subyacente de GPT-3 de su desarrollador OpenAI, pero otros usuarios pueden interactuar con él a través de una interfaz de programación de aplicaciones (API). Varios grupos, incluidos EleutherAI y Meta, han publicado interpretaciones de código abierto de GPT-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5448d",
   "metadata": {},
   "source": [
    "## Diseño de promts\n",
    "\n",
    "* Usaremos el modelo chatGPT de OpenAI, que se llama GPT 3.5 Turbo\n",
    "* Profundizaremos en más detalles sobre el formato y las entradas del chat\n",
    "\n",
    "### Ideas generales del Chat GPT 3.5\n",
    "\n",
    "En el desarrollo de grandes modelos de lenguaje (LLM), ha habido en términos generales dos tipos de LLM: LLM básicos (base LLM) y LLM ajustados por instrucción (instruction-tuned LLM). \n",
    "\n",
    "* Un base LLM ha sido entrenado para predecir la siguiente palabra basándose en datos de entrenamiento de texto, a menudo entrenado con una gran cantidad de datos de Internet y otras fuentes para determinar cuál es la siguiente palabra más probable a seguir. Por ejemplo, \"había una vez un unicornio\", ¿pueden completar esto?, ¿puede predecir la siguiente palabra?, digamos \"que vivía en un bosque mágico con todos los amigos unicornios\"\n",
    "\n",
    "* Un instruction-tuned LLM ha sido capacitado para seguir instrucciones. Por ejemplo, si le preguntará ¿cuál es la capital de Francia?, la respuesta es \"la capital de Francia es París\". Es decir, está afinado con entradas y salidas que son instrucciones\n",
    "\n",
    "Entonces, cuando utilicemos un instruction-tuned LLM piensa en darle instrucciones a otra persona, digamos a alguien que sea inteligente pero que no conozca los detalles de su tarea. \n",
    "\n",
    "Entonces, cuando un LLM no funciona, a veces es porque las instrucciones no fueron lo suficientemente claras.\n",
    "\n",
    "<img src=\"LLM.png\" alt=\"Sentiment\" width=\"600\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3196d",
   "metadata": {},
   "source": [
    "## ¿Cómo puede ayudarte el uso de Chat GPT en tu día a día?\n",
    "\n",
    "Sigue estos pincipios (o aprende a diseñar un Prompt efectivo (Prompt engineering))\n",
    "\n",
    "1. Escribe instrucciones claras y específicas y\n",
    "2. Dale tiempo al modelo para pensar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769e7ff",
   "metadata": {},
   "source": [
    "#### 1. Escribe instrucciones claras y específicas. \n",
    "\n",
    "* Expresa lo que quiere que haga un modelo proporcionando instrucciones que sean lo más claras y específicas posible. Esto guiará el modelo hacia el resultado deseado y reducirá la posibilidad de que obtengas respuestas irrelevantes o incorrectas.\n",
    "* No confundas escribir un mensaje claro con escribir un mensaje breve, porque en muchos casos, los mensajes más largos en realidad brindan más claridad y contexto para el modelo, lo que en realidad puede conducir a resultados más detallados y relevantes.\n",
    "\n",
    "Algunas estrategías: \n",
    "\n",
    "* Utiliza delimitadores para indicar claramente distintas partes de la entrada.\n",
    "\n",
    "text = \"Debe expresar lo que quiere que haga un modelo proporcionando instrucciones que sean lo más claras y específicas posible. Esto guiará el modelo hacia el resultado deseado y reducirá las posibilidades de recibir respuestas irrelevantes o incorrectas. No confunda escribir un mensaje claro con escribir un mensaje breve. En muchos casos, las indicaciones más largas brindan más claridad y contexto para el modelo, lo que puede conducir a resultados más detallados y relevantes.\"\n",
    "\n",
    "prompt = \"\n",
    "Resume el texto delimitado por triples comillas en una sola frase.\n",
    "\"\"\"{text}\"\"\" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7fdc2",
   "metadata": {},
   "source": [
    "* Pide un resultado estructurado. Para facilitar el análisis de los resultados del modelo, puede resultar útil solicitar un resultado estructurado como HTML, JSON o una lista de Python.\n",
    "\n",
    "promt = \"Genera una lista de tres títulos de libros inventados junto con sus autores y géneros. Proporciónalos en formato JSON con las siguientes claves: book_id, título, autor, género.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8910dfb",
   "metadata": {},
   "source": [
    "* Solicta al modelo que verifique si se cumplen las condiciones. Entonces, si la tarea hace suposiciones que no necesariamente se cumplen, entonces podemos decirle al modelo que verifique estas suposiciones primero. Y luego, si no están satisfechas, que lo indique y detenga el proceso antes de intentar completar la tarea por completo.\n",
    "\n",
    "text = \"¡Preparar una taza de té es fácil! Primero, necesitas poner un poco de agua a hervir. Mientras eso sucede, toma una taza y ponle una bolsita de té. Una vez que el agua esté lo suficientemente caliente, simplemente viértela sobre la bolsita de té. Déjalo reposar un rato para que el té se repose. Después de unos minutos, saca la bolsita de té. Si quieres puedes añadir un poco de azúcar o leche al gusto. ¡Y eso es! Tienes una deliciosa taza de té para disfrutar.\"\n",
    "\n",
    "promt = \"Se le proporcionará un texto delimitado por comillas triples. Si el texto contiene una secuencia de instrucciones, vuelva a escribir esas instrucciones en el siguiente formato:\n",
    "\n",
    "Paso 1 - ...\n",
    "Paso 2 - ...\n",
    "…\n",
    "Paso N - ...\n",
    "\n",
    "Si el texto no contiene una secuencia de instrucciones, simplemente escriba \"No se proporcionaron pasos\".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b5b594",
   "metadata": {},
   "source": [
    "* Proporciona ejemplos de ejecuciones exitosas de la tarea que desea realizar antes de pedirle al modelo que realice la tarea real que desea que realice.\n",
    "\n",
    "promt = \"Su tarea es responder con un estilo coherente.\n",
    "\n",
    "<niño> : Enséñame sobre la paciencia.\n",
    "\n",
    "<abuelo> : El río que labra el valle más profundo brota de un modesto manantial; la sinfonía más grandiosa se origina a partir de una sola nota; El tapiz más intrincado comienza con un hilo solitario.\n",
    "\n",
    "<niño> : Enséñame sobre la resiliencia.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300c052",
   "metadata": {},
   "source": [
    "#### Dale tiempo al modelo para pensar. \n",
    "\n",
    "Si un modelo comete errores de razonamiento al apresurarse a llegar a una conclusión incorrecta, debe intentar replantear la consulta para solicitar una cadena o serie de razonamientos relevantes antes de que el modelo proporcione su respuesta final. \n",
    "\n",
    "Otra forma de pensar en esto es que si le asignas a un modelo una tarea que es demasiado compleja para que la realice en un corto período de tiempo o en una pequeña cantidad de palabras, es posible que haga una suposición que probablemente sea incorrecta--esto también le pasaría a una persona--. \n",
    "\n",
    "Si le pide a alguien que complete una pregunta matemática compleja sin tiempo para resolver la respuesta primero, es probable que también cometa un error. \n",
    "\n",
    "Entonces, en estas situaciones, puede indicarle al modelo que piense más en un problema, lo que significa que dedica más esfuerzo computacional a la tarea.\n",
    "\n",
    "* Especifica los pasos necesarios para completar una tarea.\n",
    "\n",
    "text = \"En un pueblo encantador, los hermanos Jack y Jill emprenden una búsqueda para buscar agua de un pozo en la cima de una colina. Mientras subían, cantando alegremente, llegó la desgracia: Jack tropezó con una piedra y cayó colina abajo, y Jill hizo lo mismo. Aunque un poco golpeados, la pareja regresó a casa con abrazos reconfortantes. A pesar del percance, su espíritu aventurero permaneció intacto y continuaron explorando con deleite.\"\n",
    "\n",
    "promt = \"Realice las siguientes acciones:\n",
    "\n",
    "1 - Resume el siguiente texto delimitado por triples comillas en 1 frase.\n",
    "2 - Traduce el resumen al francés.\n",
    "3 - Enumera cada nombre en el resumen en francés.\n",
    "4 - Genera un objeto JSON que contenga las siguientes claves: french_summary, num_names.\n",
    "\n",
    "Separa tus respuestas con saltos de línea.\n",
    "\n",
    "Texto: \"\"\"{text}\"\"\" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049e9c1",
   "metadata": {},
   "source": [
    "* Instruye al modelo para que encuentre su propia solución antes de apresurarse a llegar a una conclusión. \n",
    "\n",
    "A veces obtenemos mejores resultados cuando instruimos explícitamente a los modelos a razonar su propia solución antes de llegar a una conclusión. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdc91a",
   "metadata": {},
   "source": [
    "### Limitaciones\n",
    "\n",
    "* Aunque el modelo GPT 3.5 y GPT 4 ha estado expuesto a una gran cantidad de conocimiento durante su proceso de entrenamiento, no ha memorizado perfectamente la información que ve y, por lo tanto, no conoce muy bien los límites de su conocimiento. \n",
    "\n",
    "* Esto significa que puede intentar responder preguntas sobre temas oscuros y puede inventar cosas que parecen plausibles pero que en realidad no son ciertas. \n",
    "\n",
    "* A estas ideas fabricadas las llamamos alucinaciones.\n",
    "\n",
    "* Una estrategía para reducir las alucinaciones, en el caso de que desee que el modelo genere respuestas basadas en un texto, es pedirle que primero encuentre cualquier cita relevante del texto o proporcionarle la fuente donde consultar (esto lo veremos más adelante).\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288fb480",
   "metadata": {},
   "source": [
    "## Un ejemplo más y algunas recomendaciones\n",
    "\n",
    "* Quizás me hayas oído decir que cuando entreno un modelo de aprendizaje automático, casi nunca funciona la primera vez. \n",
    "\n",
    "* Las probabilidades de que funcione la primera vez son quizás bajas, pero no importa si la primera indicación funciona, lo que más importa es el proceso para llegar a las indicaciones que funcionan para su aplicación.\n",
    "\n",
    "* Esta también es la razón por la que recomiendo no prestar tanta atención a los artículos de Internet que dicen \"Los 30 promts perfectos para ...\" \n",
    "\n",
    "* Probablemente no existe un promt perfecto para todo.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "fact_sheet_chair = \"\"\"\n",
    "OVERVIEW\n",
    "- Part of a beautiful family of mid-century inspired office furniture, \n",
    "including filing cabinets, desks, bookcases, meeting tables, and more.\n",
    "- Several options of shell color and base finishes.\n",
    "- Available with plastic back and front upholstery (SWC-100) \n",
    "or full upholstery (SWC-110) in 10 fabric and 6 leather options.\n",
    "- Base finish options are: stainless steel, matte black, \n",
    "gloss white, or chrome.\n",
    "- Chair is available with or without armrests.\n",
    "- Suitable for home or business settings.\n",
    "- Qualified for contract use.\n",
    "\n",
    "CONSTRUCTION\n",
    "- 5-wheel plastic coated aluminum base.\n",
    "- Pneumatic chair adjust for easy raise/lower action.\n",
    "\n",
    "DIMENSIONS\n",
    "- WIDTH 53 CM | 20.87”\n",
    "- DEPTH 51 CM | 20.08”\n",
    "- HEIGHT 80 CM | 31.50”\n",
    "- SEAT HEIGHT 44 CM | 17.32”\n",
    "- SEAT DEPTH 41 CM | 16.14”\n",
    "\n",
    "OPTIONS\n",
    "- Soft or hard-floor caster options.\n",
    "- Two choices of seat foam densities: \n",
    " medium (1.8 lb/ft3) or high (2.8 lb/ft3)\n",
    "- Armless or 8 position PU armrests \n",
    "\n",
    "MATERIALS\n",
    "SHELL BASE GLIDER\n",
    "- Cast Aluminum with modified nylon PA6/PA66 coating.\n",
    "- Shell thickness: 10 mm.\n",
    "SEAT\n",
    "- HD36 foam\n",
    "\n",
    "COUNTRY OF ORIGIN\n",
    "- Italy\n",
    "\"\"\"\n",
    "\n",
    "PROMT_1 = \" Tu tarea es ayudar a un equipo de marketing a crear una\n",
    "descripción de un sitio web minorista de un producto basado\n",
    "en una ficha técnica.\n",
    "\n",
    "Escribe una descripción del producto basada en la información.\n",
    "previsto en las especificaciones técnicas delimitadas por\n",
    "triples comillas invertidas.\n",
    "\n",
    "Las especificaciones técnicas son las siguientes \"{fact_sheet_chair}\" \"\n",
    "\n",
    "PROMT_1 = \" Tu tarea es ayudar a un equipo de marketing a crear una\n",
    "descripción de un sitio web minorista de un producto basado\n",
    "en una ficha técnica.\n",
    "\n",
    "Escribe una descripción del producto basada en la información.\n",
    "previsto en las especificaciones técnicas delimitadas por\n",
    "triples comillas invertidas.\n",
    "\n",
    "Utilice como máximo 50 palabras.\n",
    "\n",
    "Las especificaciones técnicas son las siguientes \"{fact_sheet_chair}\" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064af037",
   "metadata": {},
   "source": [
    "Sources:\n",
    "* https://www.deeplearning.ai/resources/natural-language-processing/\n",
    "* https://www.deeplearning.ai/short-courses/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea99d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c1dcc-1cef-42f7-9291-fa1dfa9fcc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
